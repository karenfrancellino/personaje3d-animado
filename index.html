<!DOCTYPE html>
<html lang="es">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
  <title>Droyz AR Teste</title>
  <meta name="theme-color" content="#000000">

  <!-- A-Frame + AR.js -->
  <script src="https://aframe.io/releases/1.3.0/aframe.min.js"></script>
  <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/aframe-extras@6.1.1/dist/aframe-extras.min.js"></script>

  <style>
    html,
    body {
      margin: 0;
      padding: 0;
      width: 100%;
      height: 100%;
      overflow: hidden;
      background: transparent;
      font-family: sans-serif;
    }

    .controls {
      position: fixed;
      bottom: 30px;
      left: 0;
      width: 100%;
      display: flex;
      justify-content: center;
      gap: 40px;
      z-index: 9999;
    }

    .btn {
      pointer-events: auto;
      width: 70px;
      height: 70px;
      border-radius: 50%;
      border: 3px solid white;
      background: rgba(0, 0, 0, 0.6);
      color: white;
      font-size: 28px;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: transform 0.1s;
      box-shadow: 0 4px 10px rgba(0, 0, 0, 0.5);
    }

    .btn:active {
      transform: scale(0.9);
    }

    .recording {
      background: red !important;
      border-color: red !important;
      animation: pulse 1s infinite;
    }

    @keyframes pulse {
      0% {
        box-shadow: 0 0 0 0 rgba(255, 0, 0, 0.7);
      }

      70% {
        box-shadow: 0 0 0 10px rgba(255, 0, 0, 0);
      }

      100% {
        box-shadow: 0 0 0 0 rgba(255, 0, 0, 0);
      }
    }
  </style>
</head>

<body>

  <!-- AR Scene -->
  <!-- preserveDrawingBuffer=true is mandatory for WebGL capture -->
  <a-scene embedded renderer="logarithmicDepthBuffer: true; preserveDrawingBuffer: true;"
    arjs="sourceType: webcam; debugUIEnabled: false;" id="scene">

    <a-assets>
      <a-asset-item id="skin1"
        src="https://raw.githubusercontent.com/karenfrancellino/ar-models/main/DROYZ_ANIMAPP_SiCkJacken_v005.glb"></a-asset-item>
    </a-assets>

    <!-- Camera (No Cursor needed, we use Raycaster in JS) -->
    <a-entity camera position="0 0 0"></a-entity>

    <!-- Lights -->
    <a-entity light="type: ambient; intensity: 1.3"></a-entity>
    <a-entity light="type: directional; position: 1 2 1"></a-entity>

    <!-- Character -->
    <a-entity id="personaje" gltf-model="#skin1" position="0 -0.8 -3" scale="2 2 2" animation-mixer>
    </a-entity>

  </a-scene>

  <!-- Buttons -->
  <div class="controls">
    <button id="btnFoto" class="btn">üì∏</button>
    <button id="btnVideo" class="btn">üî¥</button>
  </div>

  <script>
    const isIOS = /iPad|iPhone|iPod/.test(navigator.userAgent);
    const personaje = document.querySelector('#personaje');
    const escena = document.querySelector('a-scene');
    const btnFoto = document.getElementById('btnFoto');
    const btnVideo = document.getElementById('btnVideo');

    /* ----------------------------------------------------
       1. TOUCH MOVEMENT LOGIC (Ray-Plane Intersection)
       Moves character on X/Y plane at fixed Z=-3 depth.
    ---------------------------------------------------- */
    function onTouchMove(evt) {
      if (evt.target.tagName === 'BUTTON' || evt.target.closest('button')) return;

      const camera = escena.camera;
      if (!camera) return;

      const rect = escena.renderer.domElement.getBoundingClientRect();

      let clientX, clientY;
      if (evt.touches && evt.touches.length > 0) {
        clientX = evt.touches[0].clientX;
        clientY = evt.touches[0].clientY;
      } else {
        clientX = evt.clientX;
        clientY = evt.clientY;
      }

      if (clientX === undefined || clientY === undefined) return;

      // Normalize Mouse Position (-1 to +1)
      const mouse = new THREE.Vector2();
      mouse.x = ((clientX - rect.left) / rect.width) * 2 - 1;
      mouse.y = -((clientY - rect.top) / rect.height) * 2 + 1;

      // Raycast from Camera
      const raycaster = new THREE.Raycaster();
      raycaster.setFromCamera(mouse, camera);

      // Intersect with Plane Z = -3 (relative to camera)
      // Camera is usually at (0,0,0). So we want point P where P.z = -3.
      // Ray: P = Origin + dist * Direction
      // -3 = Origin.z + dist * Direction.z
      // dist = (-3 - Origin.z) / Direction.z

      const dir = raycaster.ray.direction;

      // If ray points behind or parallel, ignore
      if (dir.z >= -0.01) return;

      const dist = -3 / dir.z;
      const newPos = raycaster.ray.origin.clone().add(dir.clone().multiplyScalar(dist));

      // Update Position (Keep Z fixed)
      personaje.object3D.position.set(newPos.x, newPos.y, -3);
    }

    // Attach listeners to Scene Canvas
    const canvasEl = escena.renderer.domElement;
    // We listen to 'click' for taps and 'touchmove' for dragging
    canvasEl.addEventListener('click', onTouchMove);
    canvasEl.addEventListener('touchstart', onTouchMove);
    canvasEl.addEventListener('touchmove', onTouchMove);


    /* ----------------------------------------------------
       2. PHOTO COMPOSITING (Fix Black Background)
       Draws Video Feed + WebGL Scene onto a new canvas.
    ---------------------------------------------------- */
    function takeCompositePhoto() {
      const video = document.querySelector('video'); // AR.js camera feed
      const webglCanvas = escena.renderer.domElement;

      if (!webglCanvas) return null;

      const width = webglCanvas.width;
      const height = webglCanvas.height;

      const mergeCanvas = document.createElement('canvas');
      mergeCanvas.width = width;
      mergeCanvas.height = height;
      const ctx = mergeCanvas.getContext('2d');

      // A. Draw Camera Feed
      if (video && video.readyState >= 2) {
        // AR.js videos are usually full-screen object-fit:cover, but
        // drawing them raw might require aspect ratio calc. 
        // For simplicity V1, we draw stretched to fill.
        ctx.drawImage(video, 0, 0, width, height);
      } else {
        ctx.fillStyle = "#000";
        ctx.fillRect(0, 0, width, height);
      }

      // B. Draw 3D Character
      // Force render to ensure character is visible in buffer
      escena.renderer.render(escena.object3D, escena.camera);
      ctx.drawImage(webglCanvas, 0, 0, width, height);

      return mergeCanvas.toDataURL('image/png');
    }

    function sendToApp(type, dataUrl) {
      console.log(`Sending ${type} to app...`);
      const payload = JSON.stringify({ type, data: dataUrl });
      let sent = false;
      try {
        if (window.FlutterFlow && window.FlutterFlow.postMessage) {
          window.FlutterFlow.postMessage(payload);
          sent = true;
        } else if (window.flutter_inappwebview && window.flutter_inappwebview.callHandler) {
          window.flutter_inappwebview.callHandler('onCapture', payload);
          sent = true;
        } else if (window.Params && window.Params.postMessage) {
          window.Params.postMessage(payload);
          sent = true;
        }
      } catch (e) { console.error(e); }
      return sent;
    }

    /* ----------------------------------------------------
       3. BUTTON HANDLERS
    ---------------------------------------------------- */
    btnFoto.onclick = (e) => {
      e.stopPropagation();
      e.preventDefault();

      const dataUrl = takeCompositePhoto();
      const sent = sendToApp('photo', dataUrl);

      if (!sent) {
        const a = document.createElement('a');
        a.download = `Droyz_AR_${Date.now()}.png`;
        a.href = dataUrl;
        a.click();
      } else {
        alert("Foto enviada!");
      }
    };

    let isRecording = false;
    let mediaRecorder;
    let chunks = [];
    let frameId;

    btnVideo.onclick = (e) => {
      e.stopPropagation();
      e.preventDefault();

      if (isIOS) {
        alert("Grava√ß√£o de v√≠deo n√£o permitida no iOS (Web).");
        return;
      }

      if (!isRecording) {
        // --- START RECORDING ---
        // Complex logic to record blended canvas
        try {
          const webglCanvas = escena.renderer.domElement;
          const video = document.querySelector('video');

          // Recording Canvas
          const recCanvas = document.createElement('canvas');
          recCanvas.width = webglCanvas.width;
          recCanvas.height = webglCanvas.height;
          const ctx = recCanvas.getContext('2d');

          // Anim Loop to update recording canvas
          function drawLoop() {
            if (!isRecording) return;
            if (video && video.readyState >= 2) ctx.drawImage(video, 0, 0, recCanvas.width, recCanvas.height);
            ctx.drawImage(webglCanvas, 0, 0, recCanvas.width, recCanvas.height);
            frameId = requestAnimationFrame(drawLoop);
          }

          isRecording = true;
          drawLoop();

          const stream = recCanvas.captureStream(30);
          mediaRecorder = new MediaRecorder(stream, { mimeType: 'video/webm; codecs=vp8' });
          chunks = [];

          mediaRecorder.ondataavailable = e => { if (e.data.size > 0) chunks.push(e.data); };
          mediaRecorder.onstop = () => {
            const blob = new Blob(chunks, { type: 'video/webm' });
            const reader = new FileReader();
            reader.readAsDataURL(blob);
            reader.onloadend = () => {
              sendToApp('video', reader.result);
              // Alert handled or download fallback
              if (!window.FlutterFlow && !window.flutter_inappwebview) {
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = `video_${Date.now()}.webm`;
                a.click();
              } else {
                alert("V√≠deo enviado!");
              }
            }
          };

          mediaRecorder.start();
          btnVideo.textContent = '‚èπÔ∏è';
          btnVideo.classList.add('recording');

        } catch (err) {
          console.error(err);
          alert("Erro ao gravar: " + err.message);
          isRecording = false;
        }
      } else {
        // --- STOP RECORDING ---
        isRecording = false;
        cancelAnimationFrame(frameId);
        if (mediaRecorder) mediaRecorder.stop();
        btnVideo.textContent = 'üî¥';
        btnVideo.classList.remove('recording');
      }
    };
  </script>
</body>

</html>